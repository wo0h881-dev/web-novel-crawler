# naver.py : ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ ì›¹ì†Œì„¤ TOP 20 í¬ë¡¤ë§ í›„ êµ¬ê¸€ ì›¹ì•±ìœ¼ë¡œ ì „ì†¡

import os
import json
import datetime
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs

BASE = "https://series.naver.com"
RANKING_URL = (
    "https://series.naver.com/novel/top100List.series"
    "?rankingTypeCode=DAILY&categoryCode=ALL"
)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/122.0 Safari/537.36",
}

WEBAPP_URL = os.environ.get("WEBAPP_URL")  # GitHub Secrets ì—ì„œ ì£¼ì…


def get_product_no_from_href(href: str) -> str:
    qs = parse_qs(urlparse(href).query)
    return qs.get("productNo", [""])[0]


def fetch_views(detail_url: str) -> str:
    r = requests.get(detail_url, headers=HEADERS)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    for span in soup.select("span"):
        text = span.get_text(strip=True)
        if any(u in text for u in ["ë§Œ", "ì–µ"]) and any(ch.isdigit() for ch in text):
            return text
    return "-"


def fetch_naver_top20_raw():
    r = requests.get(RANKING_URL, headers=HEADERS)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    # ë„¤ì´ë²„ TOP100 ë¦¬ìŠ¤íŠ¸ li ì„ íƒì
    lis = soup.select("#content > div > ul > li")

    items = []
    for rank, li in enumerate(lis[:20], start=1):
        # ì œëª©, ìƒì„¸ ë§í¬
        a = li.select_one("div.comic_cont h3 a") or li.select_one("h3 a")
        if not a:
            continue

        title = a.get_text(strip=True)
        href = a["href"]
        if href.startswith("/"):
            href = BASE + href
        product_no = get_product_no_from_href(href)

        # ì‘ê°€
        author_tag = li.select_one("span.writer")
        author = author_tag.get_text(strip=True) if author_tag else "-"

        # ì¸ë„¤ì¼ ê·œì¹™
        thumbnail_url = f"{BASE}/novel/img/{product_no}/{product_no}.jpg"

        # ëˆ„ì  ì¡°íšŒìˆ˜
        views = fetch_views(href)

        items.append(
            {
                "rank": rank,
                "title": title,
                "author": author,
                "productNo": product_no,
                "detail_url": href,
                "thumbnail_url": thumbnail_url,
                "views": views,
            }
        )
    return items


def build_payload_for_google(raw_items):
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    result = []

    for item in raw_items:
        result.append(
            {
                "rank": f"{item['rank']}ìœ„",
                "title": item["title"],
                "author": item.get("author") or "-",
                "date": today,
                "genre": "ì›¹ì†Œì„¤",
                "views": item.get("views", "-"),
                "thumbnail": item.get("thumbnail_url", "-"),
            }
        )
    return result


def send_to_google_webapp(data):
    if not WEBAPP_URL:
        print("âŒ WEBAPP_URL í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    payload = {
        "source": "naver",          # Apps Script ì—ì„œ ì´ ê°’ìœ¼ë¡œ ë„¤ì´ë²„ ì‹œíŠ¸ ì„ íƒ
        "data": json.dumps(data),
    }

    resp = requests.post(WEBAPP_URL, data=payload)
    print("ğŸ“¡ NAVER ìƒíƒœì½”ë“œ:", resp.status_code)
    print("ğŸ“¡ NAVER ì‘ë‹µ:", resp.text)


def run_naver():
    print("ğŸš€ ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ TOP20 ìˆ˜ì§‘ ì‹œì‘...")
    raw_items = fetch_naver_top20_raw()
    data_for_sheet = build_payload_for_google(raw_items)
    send_to_google_webapp(data_for_sheet)
    print("âœ… ë„¤ì´ë²„ ì „ì†¡ ì™„ë£Œ")


if __name__ == "__main__":
    run_naver()
