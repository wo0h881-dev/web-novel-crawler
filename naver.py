# naver.py : ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ ì›¹ì†Œì„¤ TOP 20 í¬ë¡¤ë§ í›„ êµ¬ê¸€ ì›¹ì•±ìœ¼ë¡œ ì „ì†¡

import os
import json
import datetime
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs

BASE = "https://series.naver.com"
RANKING_URL = (
    "https://series.naver.com/novel/top100List.series"
    "?rankingTypeCode=DAILY&categoryCode=ALL"
)

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/122.0 Safari/537.36",
}

# GitHub Actions ì—ì„œ ë„£ì–´ì£¼ëŠ” êµ¬ê¸€ ì›¹ì•± URL
WEBAPP_URL = os.environ.get("WEBAPP_URL")


def get_product_no_from_href(href: str) -> str:
    qs = parse_qs(urlparse(href).query)
    return qs.get("productNo", [""])[0]


def fetch_detail_info(detail_url: str):
    """
    ìƒì„¸ í˜ì´ì§€ì—ì„œ ëˆ„ì  ì¡°íšŒìˆ˜, ì‘ê°€ëª…, ì¥ë¥´, ì¸ë„¤ì¼ì„ í•œ ë²ˆì— ê°€ì ¸ì˜¨ë‹¤.
    ë°˜í™˜: (views, author, genre, thumbnail_url)
    """
    r = requests.get(detail_url, headers=HEADERS)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    # 1) ì¡°íšŒìˆ˜
    views = "-"
    for span in soup.select("span"):
        text = span.get_text(strip=True)
        if any(u in text for u in ["ë§Œ", "ì–µ"]) and any(ch.isdigit() for ch in text):
            views = text
            break

    # 2) ì‘ê°€
    author = "-"
    author_label = soup.find(
        lambda tag: tag.name == "span" and tag.get_text(strip=True) == "ê¸€"
    )
    if author_label:
        a = author_label.find_next("a")
        if a:
            author = a.get_text(strip=True)
    if author == "-":
        writer_tag = soup.select_one(".writer")
        if writer_tag:
            author = writer_tag.get_text(strip=True)

    # 3) ì¥ë¥´ (info_lst ì•ˆì—ì„œ)
    genre = "ì›¹ì†Œì„¤"
    info_lst = soup.find("li", class_="info_lst")
    if info_lst:
        genre_links = info_lst.select('a[href*="genreCode="]')
        if genre_links:
            first_genre = genre_links[0].get_text(strip=True)
            if first_genre:
                genre = first_genre

    # 4) ì¸ë„¤ì¼: ìƒì„¸ ìƒë‹¨ ëŒ€í‘œ ì´ë¯¸ì§€ src (ì§€ê¸ˆ ë³´ì—¬ì¤€ êµ¬ì¡° ê¸°ì¤€)
    thumbnail_url = "-"
    # ìƒì„¸ ìƒë‹¨ì— ìˆëŠ” ì»¤ë²„ ì´ë¯¸ì§€ í•˜ë‚˜ë§Œ ì¡ê¸°
    img_tag = soup.select_one("div.pic img, div.thumb img, img#product_img, img[src*='comicthumb-phinf']")
    if img_tag and img_tag.has_attr("src"):
        thumbnail_url = img_tag["src"].strip()

    return views, author, genre, thumbnail_url



def fetch_naver_top20_raw():
    """
    ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ ì›¹ì†Œì„¤ ì¼ê°„ TOP 20ì„ ë­í‚¹ í˜ì´ì§€ + ìƒì„¸ í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘.
    """
    r = requests.get(RANKING_URL, headers=HEADERS)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    # TOP100 ë¦¬ìŠ¤íŠ¸ li ì„ íƒì
    lis = soup.select("#content > div > ul > li")

    items = []
    for rank, li in enumerate(lis[:20], start=1):
        # ì œëª© / ìƒì„¸ URL
        a = li.select_one("div.comic_cont h3 a") or li.select_one("h3 a")
        if not a:
            continue

        title = a.get_text(strip=True)
        href = a["href"]
        if href.startswith("/"):
            href = BASE + href
        product_no = get_product_no_from_href(href)

        # ì¸ë„¤ì¼ (ê·œì¹™ ê¸°ë°˜)
        thumbnail_url = f"{BASE}/novel/img/{product_no}/{product_no}.jpg"

        # ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¡°íšŒìˆ˜ / ì‘ê°€ / ì¥ë¥´
        views, author, genre = fetch_detail_info(href)

        items.append(
            {
                "rank": rank,
                "title": title,
                "author": author,
                "genre": genre,
                "productNo": product_no,
                "detail_url": href,
                "thumbnail_url": thumbnail_url,
                "views": views,
            }
        )

    return items


def build_payload_for_google(raw_items):
    """
    êµ¬ê¸€ ì›¹ì•±ì´ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
    (source: 'naver', data: JSON ë°°ì—´)
    """
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    result = []

    for item in raw_items:
        result.append(
            {
                "rank": f"{item['rank']}ìœ„",
                "title": item["title"],
                "author": item.get("author") or "-",
                "date": today,
                "genre": item.get("genre", "ì›¹ì†Œì„¤"),
                "views": item.get("views", "-"),
                "thumbnail": item.get("thumbnail_url", "-"),
            }
        )
    return result


def send_to_google_webapp(data):
    if not WEBAPP_URL:
        print("âŒ WEBAPP_URL í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    payload = {
        "source": "naver",          # Apps Script ì—ì„œ ë„¤ì´ë²„ ì‹œíŠ¸ë¡œ ë³´ë‚¼ ê¸°ì¤€
        "data": json.dumps(data),
    }

    resp = requests.post(WEBAPP_URL, data=payload)
    print("ğŸ“¡ NAVER ìƒíƒœì½”ë“œ:", resp.status_code)
    print("ğŸ“¡ NAVER ì‘ë‹µ:", resp.text)


def run_naver():
    print("ğŸš€ ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ TOP20 ìˆ˜ì§‘ ì‹œì‘...")
    raw_items = fetch_naver_top20_raw()
    data_for_sheet = build_payload_for_google(raw_items)
    send_to_google_webapp(data_for_sheet)
    print("âœ… ë„¤ì´ë²„ ì „ì†¡ ì™„ë£Œ")


if __name__ == "__main__":
    run_naver()
