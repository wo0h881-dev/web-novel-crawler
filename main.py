import os
import json
import gspread
import re
import time
from playwright.sync_api import sync_playwright

def run_total_ranking():
    print("ğŸš€ [ì—ëŸ¬ ìˆ˜ì • ë²„ì „] ìˆ˜ì§‘ ì‹œìŠ¤í…œ ê°€ë™...")
    
    try:
        creds_raw = os.environ.get('GOOGLE_CREDENTIALS')
        creds = json.loads(creds_raw)
        gc = gspread.service_account_from_dict(creds)
        # âš ï¸ ë³¸ì¸ì˜ ì‹œíŠ¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”
        sh = gc.open_by_key("1c2ax0-3t70NxvxL-cXeOCz9NYnSC9OhrzC0IOWSe5Lc").sheet1
        
        # âœ… ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ë°©ì‹ ìˆ˜ì • (ì—ëŸ¬ ë°©ì§€)
        header = ["ìˆœìœ„", "í”Œë«í¼", "íƒ€ì´í‹€", "ì‘ê°€", "ì¥ë¥´", "ì¡°íšŒìˆ˜", "ì¸ë„¤ì¼", "ìˆ˜ì§‘ì¼"]
        sh.clear()
        sh.insert_row(header, 1)
        print("âœ… ì‹œíŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ ì ‘ì†/ì´ˆê¸°í™” ì—ëŸ¬: {e}"); return

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={'width': 1280, 'height': 800}
        )

        # --- [STEP 1] ì¹´ì¹´ì˜¤í˜ì´ì§€ ---
        print("\n--- [1/2] ì¹´ì¹´ì˜¤í˜ì´ì§€ ìˆ˜ì§‘ ---")
        k_page = context.new_page()
        try:
            k_page.goto("https://page.kakao.com/menu/10011/screen/94", wait_until="domcontentloaded", timeout=60000)
            k_page.wait_for_timeout(3000)
            links = k_page.eval_on_selector_all('a[href*="/content/"]', 'elements => elements.map(e => e.href)')
            unique_links = list(dict.fromkeys(links))[:20]

            for i, link in enumerate(unique_links):
                try:
                    dp = context.new_page()
                    dp.goto(link, wait_until="domcontentloaded", timeout=20000)
                    title = dp.locator('meta[property="og:title"]').get_attribute("content") or "ì œëª©ì—†ìŒ"
                    thumb = dp.locator('meta[property="og:image"]').get_attribute("content") or ""
                    author_el = dp.locator('span.text-el-70.opacity-70').first
                    author = author_el.inner_text().strip() if author_el.count() > 0 else "-"
                    
                    genre = "-"
                    g_elements = dp.locator('span.break-all.align-middle').all_inner_texts()
                    if len(g_elements) > 1: genre = [g for g in g_elements if g != "ì›¹ì†Œì„¤"][0]
                    elif len(g_elements) == 1: genre = g_elements[0].replace("ì›¹ì†Œì„¤", "").strip()

                    body = dp.evaluate("() => document.body.innerText")
                    views = re.search(r'(\d+\.?\d*[ë§Œ|ì–µ])', body).group(1) if re.search(r'(\d+\.?\d*[ë§Œ|ì–µ])', body) else "-"
                    
                    sh.append_row([f"{i+1}ìœ„", "ì¹´ì¹´ì˜¤í˜ì´ì§€", title, author, genre, views, thumb, "2026-02-25"])
                    print(f"   âœ… ì¹´ì¹´ì˜¤ {i+1}ìœ„: {title}")
                    dp.close()
                except: continue
        except Exception as e: print(f"âŒ ì¹´ì¹´ì˜¤ ë©”ì¸ ì—ëŸ¬: {e}")

        # --- [STEP 2] ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ ---
        print("\n--- [2/2] ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ ìˆ˜ì§‘ ---")
        n_page = context.new_page()
        try:
            # í•´ì™¸ IP ì°¨ë‹¨ ëŒ€ë¹„ë¥¼ ìœ„í•´ PC ë­í‚¹ ì£¼ì†Œ ì‚¬ìš©
            n_page.goto("https://series.naver.com/novel/top100List.series", wait_until="domcontentloaded", timeout=60000)
            n_page.wait_for_timeout(5000)
            
            items = n_page.locator('ul.lst_list > li, div.lst_list_wrap li').all()
            if not items:
                print("   âš ï¸ PC ë²„ì „ ì‘ë‹µ ì—†ìŒ, ëª¨ë°”ì¼ ì¬ì‹œë„...")
                n_page.goto("https://m.series.naver.com/novel/top100List.series", wait_until="domcontentloaded", timeout=60000)
                n_page.wait_for_timeout(5000)
                items = n_page.locator('a.comic_top_ba, ul.lst_list > li').all()

            print(f"   ğŸ” ë„¤ì´ë²„ ë°œê²¬ í•­ëª©: {len(items)}ê°œ")

            for i, item in enumerate(items[:20]):
                try:
                    title_el = item.locator('h3 a, dt a, h5.tit, .tit, strong').first
                    title = title_el.inner_text().replace("ìƒˆë¡œìš´ ì—í”¼ì†Œë“œ", "").strip()
                    
                    # ì‘ê°€ ë° ì¸ë„¤ì¼
                    author = item.locator('.author, .wt, span.author').first.inner_text().strip()
                    thumb = item.locator('img').first.get_attribute('src') or ""
                    
                    # ìƒì„¸í˜ì´ì§€ ì´ë™ (ì¡°íšŒìˆ˜)
                    href = title_el.get_attribute('href') or item.locator('a').first.get_attribute('href')
                    full_href = href if href.startswith('http') else f"https://series.naver.com{href}"
                    
                    dp = context.new_page()
                    dp.goto(full_href, wait_until="domcontentloaded", timeout=20000)
                    dp_text = dp.evaluate("() => document.body.innerText")
                    views = re.search(r'(\d+\.?\d*[ë§Œ|ì–µ])', dp_text).group(1) if re.search(r'(\d+\.?\d*[ë§Œ|ì–µ])', dp_text) else "-"
                    
                    sh.append_row([f"{i+1}ìœ„", "ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ", title, author, "ì›¹ì†Œì„¤", views, thumb, "2026-02-25"])
                    print(f"   âœ… ë„¤ì´ë²„ {i+1}ìœ„: {title}")
                    dp.close()
                except: continue
        except Exception as e: print(f"âŒ ë„¤ì´ë²„ ë©”ì¸ ì—ëŸ¬: {e}")

        browser.close()
        print("\nğŸŠ ëª¨ë“  ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")

if __name__ == "__main__":
    run_total_ranking()
