import os
import json
import gspread
import re
from playwright.sync_api import sync_playwright

# --- [ì¹´ì¹´ì˜¤ ìˆ˜ì§‘ í•¨ìˆ˜] ---
def get_kakao_data(context):
    print("      ì¹´ì¹´ì˜¤í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
    data = []
    page = context.new_page()
    url = "https://page.kakao.com/menu/10011/screen/94"
    try:
        page.goto(url, wait_until="networkidle")
        page.wait_for_timeout(4000)
        
        links = page.eval_on_selector_all('a[href*="/content/"]', 'elements => elements.map(e => e.href)')
        unique_links = []
        for link in links:
            if link not in unique_links: unique_links.append(link)
        
        for i, link in enumerate(unique_links[:20]):
            try:
                d_page = context.new_page()
                d_page.goto(link, wait_until="networkidle")
                d_page.wait_for_timeout(2000)
                
                title = d_page.locator('meta[property="og:title"]').get_attribute("content")
                thumbnail = d_page.locator('meta[property="og:image"]').get_attribute("content")
                author = d_page.locator('span.text-el-70.opacity-70').first.inner_text().strip()
                
                # ì¹´ì¹´ì˜¤ ì¥ë¥´ í•„í„°ë§
                genre = "-"
                genre_elements = d_page.locator('span.break-all.align-middle').all_inner_texts()
                if len(genre_elements) > 1:
                    genre = [g for g in genre_elements if g != "ì›¹ì†Œì„¤"][0]
                elif len(genre_elements) == 1:
                    genre = genre_elements[0].replace("ì›¹ì†Œì„¤", "").strip()

                view_match = re.search(r'(\d+\.?\d*[ë§Œ|ì–µ])', d_page.evaluate("() => document.body.innerText"))
                views = view_match.group(1) if view_match else "-"
                
                data.append([f"{i+1}ìœ„", "ì¹´ì¹´ì˜¤í˜ì´ì§€", title, author, genre, views, thumbnail, "2026-02-25"])
                d_page.close()
            except: continue
    except Exception as e:
        print(f"âŒ ì¹´ì¹´ì˜¤ ì—ëŸ¬: {e}")
    page.close()
    return data

# --- [ë„¤ì´ë²„ ìˆ˜ì§‘ í•¨ìˆ˜: ì •ë°€ ë³´ì • ë²„ì „] ---
def get_naver_data(context):
    print("      ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ ìˆ˜ì§‘ ì‹œì‘...")
    data = []
    page = context.new_page()
    
    # ë„¤ì´ë²„ ì‹¤ì‹œê°„ ì „ì²´ ë­í‚¹
    url = "https://series.naver.com/novel/top100List.series?rankingTypeCode=REALTIME&categoryCode=ALL"
    
    try:
        # ë„¤ì´ë²„ê°€ ë´‡ìœ¼ë¡œ ì¸ì‹í•˜ì§€ ì•Šë„ë¡ ì„¸ì…˜ ìœ ì§€ ë° ëŒ€ê¸°
        page.goto(url, wait_until="networkidle")
        page.wait_for_timeout(4000)

        # [ìˆ˜ì •] ë„¤ì´ë²„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ëŠ” ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•: í´ë˜ìŠ¤ëª…ì— 'lst_list'ê°€ í¬í•¨ëœ ëª¨ë“  li ì°¾ê¸°
        items = page.locator('ul[class*="lst_list"] > li').all()
        
        # ë§Œì•½ ì—¬ì „íˆ 0ê°œë¼ë©´, ë‹¤ë¥¸ ê²½ë¡œë¡œ í•œ ë²ˆ ë” ì‹œë„
        if len(items) == 0:
            items = page.locator('.lst_list_wrap li').all()
            
        print(f"      ğŸ” ë°œê²¬ëœ ì‘í’ˆ ìˆ˜: {len(items)}ê°œ")

        for i, item in enumerate(items[:20]):
            try:
                # 1. ê¸°ë³¸ ì •ë³´ (ì œëª©/ì‘ê°€/ì¸ë„¤ì¼/ì¥ë¥´)
                # ì œëª© íƒœê·¸ê°€ ë³µì¡í•  ìˆ˜ ìˆì–´ ë‚´ë¶€ì˜ a íƒœê·¸ë¥¼ ì •í™•íˆ ì§€ì¹­
                title_link = item.locator('h3 a, dt a').first
                title = title_link.inner_text().strip()
                href = title_link.get_attribute('href')
                
                author = item.locator('span.author').inner_text().strip()
                thumbnail = item.locator('img').get_attribute("src")
                genre = item.locator('span.genre').inner_text().strip() if item.locator('span.genre').count() > 0 else "-"
                
                # 2. ìƒì„¸ í˜ì´ì§€ ì ‘ì† (ì¡°íšŒìˆ˜ 40.4ë§Œ ìˆ˜ì§‘)
                detail_url = f"https://series.naver.com{href}"
                d_page = context.new_page()
                d_page.goto(detail_url, wait_until="domcontentloaded")
                d_page.wait_for_timeout(2000)
                
                # [í•µì‹¬] ì‚¬ìš©ìë‹˜ì´ ì•Œë ¤ì£¼ì‹  <span>40.4ë§Œ</span> í˜•íƒœ ì •ë°€ ì¡°ì¤€
                views = "-"
                # ìƒì„¸ í˜ì´ì§€ ë‚´ ëª¨ë“  span ì¤‘ì—ì„œ 'ë§Œ' í˜¹ì€ 'ì–µ'ì´ ë“¤ì–´ê°„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                view_spans = d_page.locator('span:has-text("ë§Œ"), span:has-text("ì–µ")').all()
                for span in view_spans:
                    text = span.inner_text()
                    if re.search(r'\d+\.?\d*[ë§Œ|ì–µ]', text):
                        views = text.strip()
                        break
                
                data.append([f"{i+1}ìœ„", "ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ", title, author, genre, views, thumbnail, "2026-02-25"])
                print(f"      âœ… {i+1}ìœ„ ì™„ë£Œ: {title} ({views})")
                d_page.close()
            except Exception as e:
                print(f"      âš ï¸ ê°œë³„ í•­ëª© ì˜¤ë¥˜: {e}")
                continue
                
    except Exception as e:
        print(f"      âŒ ë„¤ì´ë²„ ì ‘ì† ì—ëŸ¬: {e}")
    
    page.close()
    return data

def run_total_ranking():
    # ì‹œíŠ¸ ì—°ê²° ë° ì‹¤í–‰ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ë¶€ë¶„ í™•ì¸)
    # ... (ìƒëµëœ ê¸°ì¡´ run_total_ranking ì½”ë“œ)
    
    try:
        creds = json.loads(os.environ['GOOGLE_CREDENTIALS'])
        gc = gspread.service_account_from_dict(creds)
        sh = gc.open_by_key("1c2ax0-3t70NxvxL-cXeOCz9NYnSC9OhrzC0IOWSe5Lc").sheet1
    except Exception as e:
        print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36")
        
        # 1. ë„¤ì´ë²„ ë°ì´í„° ìˆ˜ì§‘ (ì¹´ì¹´ì˜¤ê°€ í•„ìš”í•˜ë©´ ì—¬ê¸°ì— get_kakao_data(context) ì¶”ê°€)
        naver_results = get_naver_data(context)
        
        # 2. í—¤ë” ë° ë°ì´í„° ë³‘í•©
        header = [["ìˆœìœ„", "í”Œë«í¼", "íƒ€ì´í‹€", "ì‘ê°€", "ì¥ë¥´", "ì¡°íšŒìˆ˜", "ì¸ë„¤ì¼", "ìˆ˜ì§‘ì¼"]]
        final_list = header + naver_results # ì¹´ì¹´ì˜¤ê°€ ìˆë‹¤ë©´ ì¤‘ê°„ì— ì¶”ê°€
        
        # 3. ì‹œíŠ¸ ê¸°ë¡
        sh.clear()
        sh.update('A1', final_list)
        print(f"ğŸŠ ì™„ë£Œ! ì´ {len(naver_results)}ê°œì˜ ë„¤ì´ë²„ ë°ì´í„°ê°€ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        browser.close()

if __name__ == "__main__":
    run_total_ranking()
